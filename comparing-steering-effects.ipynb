{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/activation-additions-large-models/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.extract_utils import average_vectors, gather_activations_from_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformers, accelerate, einops, json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_utils import load_gpt_model_and_tokeniser\n",
    "\n",
    "from src.utils.extract_utils import create_steering_vector, create_mc_unmc_steering_vector\n",
    "\n",
    "from src.utils.intervention_utils import steering_natural_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.54s/it]\n",
      "/root/activation-additions-large-models/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, MODEL_CONFIG = load_gpt_model_and_tokeniser(model_name=\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "# model, tokenizer, MODEL_CONFIG = load_gpt_model_and_tokeniser(model_name=\"gpt2-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.intervention_utils as iu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = {}\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('datasets/fantasy.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_fantasy = json.load(file)\n",
    "\n",
    "  stories[\"fantasy\"] = dataset_fantasy\n",
    "\n",
    "with open('datasets/scifi.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_scifi = json.load(file)\n",
    "\n",
    "  stories[\"scifi\"] = dataset_scifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset_utils import read_all_text_files\n",
    "\n",
    "training_dataset = read_all_text_files(\"datasets/opentext_subset\")\n",
    "\n",
    "# Cut texts for first 200 tokens\n",
    "# Determine the cutoff point using the tokenizer\n",
    "if 'llama' in MODEL_CONFIG['name_or_path']:\n",
    "    training_dataset = [tokenizer.decode(tokenizer.encode(text)[:200])[4:] for text in training_dataset][:400]\n",
    "else:\n",
    "    training_dataset = [tokenizer.decode(tokenizer.encode(text)[:200]) for text in training_dataset][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Massimo Cellino’s near three-year ownership of Leeds United could be set to come to a close amid a string of reports in the Italian media on Wednesday.\\n\\nThe Italian’s tenure at Elland Road has been nothing short of tumultuous and news that Cellino – through his family’s trust Eleonora Sport Ltd – is set to relinquish his holdings at the club will come as a huge relief to their supporters who have long campaigned to have him removed.\\n\\nAccording to calciomercato, Cellino is understood to have agreed the sale of Leeds to another Italian, Andrea Radrizzani, who is the president of the MP & Silva Media empire.\\n\\nRadrizzani has been seen at several Leeds games recently and his purchase of the club would not come as a huge shock to those who have been following the Cellino saga closely.\\n\\nThe Italian'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering activations: 100%|██████████| 200/200 [00:46<00:00,  4.34it/s]\n",
      "Gathering activations: 100%|██████████| 300/300 [01:20<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "mc_steering_vector, un_mc_steering_vector = create_mc_unmc_steering_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    MODEL_CONFIG,\n",
    "    dataset_fantasy,\n",
    "    training_dataset[:300],\n",
    "    [\"layer_hook_names\"],\n",
    "    False,\n",
    "    False,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering activations: 100%|██████████| 200/200 [00:44<00:00,  4.46it/s]\n",
      "Gathering activations: 100%|██████████| 300/300 [01:18<00:00,  3.80it/s]\n"
     ]
    }
   ],
   "source": [
    "scifi_mc_steering_vector, scifi_un_mc_steering_vector = create_mc_unmc_steering_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    MODEL_CONFIG,\n",
    "    dataset_scifi,\n",
    "    training_dataset[:300],\n",
    "    [\"layer_hook_names\"],\n",
    "    False,\n",
    "    False,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Steering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:37<00:00, 12.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Clearlu should just make num_beams smaller!!!\n",
    "\n",
    "un_mc_outputs = steering_natural_text(\n",
    "    \"Here is a story:\", \n",
    "    25,\n",
    "    un_mc_steering_vector[25], \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA few years ago, I was working on a project with a group of people. We were trying to figure out how to do something that had never been done before. The problem was that we didn’t know how to do it, and we didn’t know where to start. So we decided to brainstorm.\\nWe sat down in a room and started throwing out ideas. We came up with all sorts of different ways to do it, but none of them seemed right.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_mc_outputs[\"clean\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:38<00:00, 12.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Clearlu should just make num_beams smaller!!!\n",
    "\n",
    "outputs2 = steering_natural_text(\n",
    "    \"Yesterday, my son was out kicking a football. Then,\", \n",
    "    25,\n",
    "    un_mc_steering_vector[25] * 2.7, \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he came inside and the first thing he said to me was, “ I wish I had a magic wand. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better place. I would mag the world into a better'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2[\"steered\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:37<00:00, 12.66s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs3 = steering_natural_text(\n",
    "    \"Yesterday, my son was out kicking a football. Then,\", \n",
    "    25,\n",
    "    steering_vector[25] * 3, \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he came inside and told me that he had found a strange creature in the garden. I rushed outside to see what it was. It turned out to be a magical creature called a unicorn.\\nThe unicorn was enchanting and majestic. She glowed with a magical light, and her horn shimmered with magic. Her eyes sparkled like stars, and her mane danced in the breeze. The unicorn seemed to radi'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3[\"steered\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In the flickering glow of his multi-monitor setup, Alex, a skilled computer hacker, hunched over his keyboard. His world was a digital maze of codes and firewalls. Tonight, he was on a mission to expose corrupt corporate secrets. With each keystroke, he danced through layers of security, his fingers a blur of motion. The clock ticked ominously, reminding him of the race against time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:45<00:00, 15.00s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs4 = steering_natural_text(\n",
    "    prompt, \n",
    "    25,\n",
    "    steering_vector[25] * 2, \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs he delved deeper into the forbidden realm, an unsettling sense of danger crept upon him. He sensed that something dark and sinister lurked in the shadows, ready to pounce upon him at any moment. Her eyes pierced through the darkness, like twin beams of light, searching for her prey. She had been watching him for days, waiting for the perfect opportunity to strike. And tonight, she knew, was the night'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs4[\"steered\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:43<00:00, 14.54s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs5 = steering_natural_text(\n",
    "    prompt, \n",
    "    28,\n",
    "    steering_vector[28]*1.5, \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs he delved deeper into the forbidden realm, he felt a strange presence lurking in the shadows. He knew he was being watched, yet no one could see him. A chill crept down his spine as he sensed something dark and sinister lurking in the darkness.\\nSuddenly, a bright light illuminated the room, blinding him for a moment. When he regained his vision, he found himself staring into'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs5[\"steered\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scifi Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5882)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(scifi_mc_steering_vector[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:37<00:00, 12.55s/it]\n"
     ]
    }
   ],
   "source": [
    "un_mc_outputs = steering_natural_text(\n",
    "    \"Here is a story:\", \n",
    "    13,\n",
    "    1.7 * scifi_un_mc_steering_vector[13], \n",
    "    model,\n",
    "    MODEL_CONFIG, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n surely, it’s not the first time.\\nI was born in 1...\\nA few years ago, I decided to go on an adventure. It was one of the most exc...\\nIt's been 2500000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_mc_outputs[\"steered\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
