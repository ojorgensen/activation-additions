{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f12b4a03cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json\n",
    "import torch, numpy as np\n",
    "\n",
    "import sys\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/activation-additions-large-models/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.model_utils import load_gpt_model_and_tokeniser\n",
    "\n",
    "from src.utils.prompt_utils import load_dataset\n",
    "\n",
    "from src.utils.extract_utils import create_steering_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'EleutherAI/gpt-j-6b'\n",
    "model, tokenizer, model_config = load_gpt_model_and_tokeniser(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('antonym',\n",
    "                       'dataset_files',\n",
    "                       test_size=0.3,\n",
    "                        seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2302 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "stories = {}\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('datasets/fantasy.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_fantasy = json.load(file)\n",
    "\n",
    "  stories[\"fantasy\"] = dataset_fantasy\n",
    "\n",
    "with open('datasets/scifi.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_scifi = json.load(file)\n",
    "\n",
    "  stories[\"scifi\"] = dataset_scifi\n",
    "\n",
    "\n",
    "from src.utils.dataset_utils import read_all_text_files\n",
    "\n",
    "training_dataset = read_all_text_files(\"datasets/opentext_subset\")\n",
    "\n",
    "# Cut texts for first 200 tokens\n",
    "# Determine the cutoff point using the tokenizer\n",
    "training_dataset = [tokenizer.decode(tokenizer.encode(text)[:200])[4:] for text in training_dataset][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering activations:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering activations: 100%|██████████| 200/200 [00:29<00:00,  6.72it/s]\n",
      "Gathering activations: 100%|██████████| 400/400 [01:25<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "steering_vector = create_steering_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    model_config,\n",
    "    dataset_fantasy,\n",
    "    training_dataset,\n",
    "    [\"layer_hook_names\"],\n",
    "    False,\n",
    "    False,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config[\"n_layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 4096])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:35<00:00, 19.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.intervention_utils import steering_natural_text\n",
    "\n",
    "outputs = steering_natural_text(\n",
    "    \"Here is a story:\", \n",
    "    23,\n",
    "    steering_vector[23], \n",
    "    model,\n",
    "    model_config, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=5,\n",
    "    n_beams=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n� \"We are going to get this guy, and we are going to get the guys on top of that. We are going to get them all. � (I) really think it is going to work. I really do. I really think it is going to work. I really do. I really think it is going to work. I really do. I really think it is going to work. I really do. I really think it is going to work. I really do'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['steered'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
