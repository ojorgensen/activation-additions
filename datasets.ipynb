{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f096d47ba60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json\n",
    "import torch, numpy as np\n",
    "\n",
    "import sys\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/activation-additions-large-models/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.model_utils import load_gpt_model_and_tokeniser\n",
    "\n",
    "from src.utils.prompt_utils import load_dataset\n",
    "\n",
    "from src.utils.extract_utils import create_steering_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'EleutherAI/gpt-j-6b'\n",
    "model, tokenizer, model_config = load_gpt_model_and_tokeniser(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('antonym',\n",
    "                       'dataset_files',\n",
    "                       test_size=0.3,\n",
    "                        seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = {}\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('datasets/fantasy.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_fantasy = json.load(file)\n",
    "\n",
    "  stories[\"fantasy\"] = dataset_fantasy\n",
    "\n",
    "with open('datasets/scifi.json', 'r') as file:\n",
    "  # Load the JSON data from the file\n",
    "  dataset_scifi = json.load(file)\n",
    "\n",
    "  stories[\"scifi\"] = dataset_scifi\n",
    "\n",
    "\n",
    "from src.utils.dataset_utils import read_all_text_files\n",
    "\n",
    "training_dataset = read_all_text_files(\"datasets/opentext_subset\")\n",
    "\n",
    "# Cut texts for first 200 tokens\n",
    "# Determine the cutoff point using the tokenizer\n",
    "if 'llama' in model_config['name_or_path']:\n",
    "    training_dataset = [tokenizer.decode(tokenizer.encode(text)[:200])[4:] for text in training_dataset][:400]\n",
    "else:\n",
    "    training_dataset = [tokenizer.decode(tokenizer.encode(text)[:200]) for text in training_dataset][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Massimo Cellino’s near three-year ownership of Leeds United could be set to come to a close amid a string of reports in the Italian media on Wednesday.\\n\\nThe Italian’s tenure at Elland Road has been nothing short of tumultuous and news that Cellino – through his family’s trust Eleonora Sport Ltd – is set to relinquish his holdings at the club will come as a huge relief to their supporters who have long campaigned to have him removed.\\n\\nAccording to calciomercato, Cellino is understood to have agreed the sale of Leeds to another Italian, Andrea Radrizzani, who is the president of the MP & Silva Media empire.\\n\\nRadrizzani has been seen at several Leeds games recently and his purchase of the club would not come as a huge shock to those who have been following the Cellino saga closely.\\n\\nThe Italian publication also understands that Cellino is drawing closer to becoming a major shareholder'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering activations: 100%|██████████| 200/200 [00:31<00:00,  6.35it/s]\n",
      "Gathering activations: 100%|██████████| 400/400 [01:25<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "steering_vector = create_steering_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    model_config,\n",
    "    dataset_fantasy,\n",
    "    training_dataset,\n",
    "    [\"layer_hook_names\"],\n",
    "    False,\n",
    "    False,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config[\"n_layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 4096])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside: GPT-J example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:46<00:00, 15.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.intervention_utils import steering_natural_text\n",
    "\n",
    "outputs = steering_natural_text(\n",
    "    \"Here is a story:\", \n",
    "    12,\n",
    "    steering_vector[12] * 3, \n",
    "    model,\n",
    "    model_config, \n",
    "    tokenizer, \n",
    "    max_new_tokens=100, \n",
    "    temperature=1.0, \n",
    "    freq_penalty=2.0,\n",
    "    top_p=0.3,\n",
    "    n_completions=3,\n",
    "    n_beams=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nA young girl was born with a gift. She could see the world, and she knew that her destiny was to become a warrior. She set out on a quest to find a powerful sword, but it was not long until she discovered a new power. She had been chosen to be the last guardian of an ancient kingdom, and together with her best friend, she set off on a journey to fulfill her destiny. But as she journeyed through the land, she learned of a terrible evil'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['steered'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Vector Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.prompt_utils import word_pairs_to_prompt_data, create_prompt\n",
    "\n",
    "from src.utils.eval_utils import decode_to_vocab, sentence_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_vector_evaluation(\n",
    "    eval_datasets,\n",
    "    training_dataset,\n",
    "    edit_layer,\n",
    "    n_shots,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    model_config,   \n",
    "):\n",
    "    results = {}\n",
    "    for eval_dataset in tqdm(eval_datasets):\n",
    "        \n",
    "        # Sample from the dataset to create a steering vector\n",
    "        # Use 100 samples of 10-shot prompts,\n",
    "        # TODO: Make these parameters / check what is used in the original paper\n",
    "        \n",
    "\n",
    "        # Create mean-centred steering vector\n",
    "        mc_fv, og_fv = create_mc_unmc_steering_vector(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            model_config,\n",
    "            place_holder,\n",
    "            training_dataset,\n",
    "            [\"layer_hook_names\"], \n",
    "            False,\n",
    "            True,\n",
    "            False\n",
    "        )\n",
    "\n",
    "        # Perform evaluations with mean-centred steering vector\n",
    "\n",
    "        results[\"string\"][\"mc\"] = n_shot_eval(dataset=dataset, fv_vector=mc_fv, edit_layer=edit_layer, n_shots=n_shots, \n",
    "                                model=model, model_config=model_config, tokenizer=tokenizer, filter_set=filter_set)\n",
    "        \n",
    "        results[\"string\"][\"unmc\"] = n_shot_eval(dataset=dataset, fv_vector=og_fv, edit_layer=edit_layer, n_shots=n_shots,\n",
    "                                model=model, model_config=model_config, tokenizer=tokenizer, filter_set=filter_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL prompt:\n",
      " '<|endoftext|>Q: limitless\\nA: limited\\n\\nQ: wake\\nA: sleep\\n\\nQ: elevate\\nA: depress\\n\\nQ: push\\nA: pull\\n\\nQ: stale\\nA: fresh\\n\\nQ: static\\nA:' \n",
      "\n",
      "\n",
      "Shuffled ICL Prompt:\n",
      " '<|endoftext|>Q: limitless\\nA: limited\\n\\nQ: wake\\nA: pull\\n\\nQ: elevate\\nA: fresh\\n\\nQ: push\\nA: sleep\\n\\nQ: stale\\nA: depress\\n\\nQ: static\\nA:' \n",
      "\n",
      "\n",
      "Zero-Shot Prompt:\n",
      " '<|endoftext|>Q: static\\nA:'\n"
     ]
    }
   ],
   "source": [
    "# Sample ICL example pairs, and a test word\n",
    "dataset = load_dataset('antonym', 'dataset_files', test_size=0.3, seed=0)\n",
    "word_pairs = dataset['train'][:5]\n",
    "test_pair = dataset['test'][21]\n",
    "\n",
    "prompt_data = word_pairs_to_prompt_data(word_pairs, query_target_pair=test_pair, prepend_bos_token=True)\n",
    "sentence = create_prompt(prompt_data)\n",
    "print(\"ICL prompt:\\n\", repr(sentence), '\\n\\n')\n",
    "\n",
    "shuffled_prompt_data = word_pairs_to_prompt_data(word_pairs, query_target_pair=test_pair, prepend_bos_token=True, shuffle_labels=True)\n",
    "shuffled_sentence = create_prompt(shuffled_prompt_data)\n",
    "print(\"Shuffled ICL Prompt:\\n\", repr(shuffled_sentence), '\\n\\n')\n",
    "\n",
    "zeroshot_prompt_data = word_pairs_to_prompt_data({'input':[], 'output':[]}, query_target_pair=test_pair, prepend_bos_token=True, shuffle_labels=True)\n",
    "zeroshot_sentence = create_prompt(zeroshot_prompt_data)\n",
    "print(\"Zero-Shot Prompt:\\n\", repr(zeroshot_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: '<|endoftext|>Q: limitless\\nA: limited\\n\\nQ: wake\\nA: sleep\\n\\nQ: elevate\\nA: depress\\n\\nQ: push\\nA: pull\\n\\nQ: stale\\nA: fresh\\n\\nQ: static\\nA:' \n",
      "\n",
      "Input Query: 'static', Target: 'dynamic'\n",
      "\n",
      "ICL Prompt Top K Vocab Probs:\n",
      " [(' dynamic', 0.82726), (' fluid', 0.01458), (' dynam', 0.0124), (' moving', 0.01145), (' static', 0.00887)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model's ICL answer\n",
    "clean_logits = sentence_eval(sentence, [test_pair['output']], model, tokenizer, compute_nll=False)\n",
    "\n",
    "print(\"Input Sentence:\", repr(sentence), '\\n')\n",
    "print(f\"Input Query: {repr(test_pair['input'])}, Target: {repr(test_pair['output'])}\\n\")\n",
    "print(\"ICL Prompt Top K Vocab Probs:\\n\", decode_to_vocab(clean_logits, tokenizer, k=5), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
